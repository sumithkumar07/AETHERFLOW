#!/usr/bin/env python3
"""
Comprehensive Test Suite for Ollama Local AI Integration
Tests all aspects of the unlimited local AI implementation
"""

import asyncio
import httpx
import json
import time
from datetime import datetime

class OllamaIntegrationTester:
    def __init__(self):
        self.backend_url = "http://localhost:8001"
        self.ollama_url = "http://localhost:11434"
        self.access_token = None
        self.test_results = []

    async def run_all_tests(self):
        """Run comprehensive test suite"""
        print("üöÄ Starting Ollama Local AI Integration Tests...")
        print("=" * 60)
        
        # Test suite
        tests = [
            ("Ollama Server Connection", self.test_ollama_connection),
            ("Backend API Health", self.test_backend_health),
            ("User Authentication", self.test_authentication),
            ("Model Availability", self.test_model_availability),
            ("Agent Configuration", self.test_agent_configuration),
            ("AI Chat - CodeLlama", self.test_codellama_chat),
            ("AI Chat - LLaMA General", self.test_llama_chat),
            ("AI Chat - DeepSeek Fast", self.test_deepseek_chat),
            ("Multiple Agents Test", self.test_multiple_agents),
            ("Unlimited Usage Test", self.test_unlimited_usage),
            ("Model Status Check", self.test_model_status),
            ("Privacy Validation", self.test_privacy_features)
        ]
        
        for test_name, test_func in tests:
            print(f"\nüß™ Running: {test_name}")
            try:
                start_time = time.time()
                result = await test_func()
                duration = time.time() - start_time
                
                if result:
                    print(f"   ‚úÖ PASSED ({duration:.2f}s)")
                    self.test_results.append({"test": test_name, "status": "PASSED", "duration": duration})
                else:
                    print(f"   ‚ùå FAILED ({duration:.2f}s)")
                    self.test_results.append({"test": test_name, "status": "FAILED", "duration": duration})
                    
            except Exception as e:
                print(f"   üí• ERROR: {str(e)}")
                self.test_results.append({"test": test_name, "status": "ERROR", "error": str(e)})
        
        # Print final results
        self.print_test_summary()

    async def test_ollama_connection(self):
        """Test direct Ollama server connection"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.ollama_url}/api/tags", timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])
                    print(f"   ü§ñ Found {len(models)} models: {[m['name'] for m in models]}")
                    return len(models) >= 3
                return False
        except Exception as e:
            print(f"   ‚ùå Connection failed: {e}")
            return False

    async def test_backend_health(self):
        """Test backend API health"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.backend_url}/api/health", timeout=10.0)
                if response.status_code == 200:
                    health = response.json()
                    print(f"   üíö Backend status: {health.get('status')}")
                    return health.get("status") == "healthy"
                return False
        except Exception as e:
            print(f"   ‚ùå Backend health check failed: {e}")
            return False

    async def test_authentication(self):
        """Test user authentication"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.backend_url}/api/auth/login",
                    json={"email": "demo@aicodestudio.com", "password": "demo123"},
                    timeout=10.0
                )
                if response.status_code == 200:
                    data = response.json()
                    self.access_token = data.get("access_token")
                    print(f"   üîê Authenticated as: {data.get('user', {}).get('email')}")
                    return bool(self.access_token)
                return False
        except Exception as e:
            print(f"   ‚ùå Authentication failed: {e}")
            return False

    async def test_model_availability(self):
        """Test local model availability"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.backend_url}/api/ai/models", timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])
                    
                    expected_models = ["codellama:13b", "llama3.1:8b", "deepseek-coder:6.7b"]
                    available_models = [m["id"] for m in models]
                    
                    print(f"   üéØ Available models: {available_models}")
                    print(f"   üè† Local processing: {data.get('local_processing')}")
                    print(f"   ‚ôæÔ∏è  Unlimited usage: {data.get('unlimited_usage')}")
                    
                    return all(model in available_models for model in expected_models)
                return False
        except Exception as e:
            print(f"   ‚ùå Model availability check failed: {e}")
            return False

    async def test_agent_configuration(self):
        """Test AI agent configuration"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.backend_url}/api/ai/agents", timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    agents = data.get("agents", [])
                    
                    expected_agents = ["developer", "designer", "tester", "integrator", "analyst"]
                    available_agents = [a["id"] for a in agents]
                    
                    print(f"   üë• Available agents: {available_agents}")
                    
                    # Check for unlimited and local flags
                    all_unlimited = all(agent.get("unlimited", False) for agent in agents)
                    all_local = all(agent.get("local", False) for agent in agents)
                    
                    print(f"   ‚ôæÔ∏è  All agents unlimited: {all_unlimited}")
                    print(f"   üè† All agents local: {all_local}")
                    
                    return (all(agent in available_agents for agent in expected_agents) and
                            all_unlimited and all_local)
                return False
        except Exception as e:
            print(f"   ‚ùå Agent configuration check failed: {e}")
            return False

    async def test_codellama_chat(self):
        """Test CodeLlama chat functionality"""
        if not self.access_token:
            return False
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.backend_url}/api/ai/chat",
                    headers={"Authorization": f"Bearer {self.access_token}"},
                    json={
                        "message": "Write a Python function to calculate factorial",
                        "model": "codellama:13b",
                        "agent": "developer"
                    },
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    response_text = data.get("response", "")
                    model_used = data.get("model_used", "")
                    
                    print(f"   ü§ñ Model used: {model_used}")
                    print(f"   üìù Response length: {len(response_text)} characters")
                    print(f"   üíª Contains code: {'```' in response_text}")
                    
                    return "codellama" in model_used.lower() and len(response_text) > 100
                return False
        except Exception as e:
            print(f"   ‚ùå CodeLlama chat test failed: {e}")
            return False

    async def test_llama_chat(self):
        """Test LLaMA general chat functionality"""
        if not self.access_token:
            return False
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.backend_url}/api/ai/chat",
                    headers={"Authorization": f"Bearer {self.access_token}"},
                    json={
                        "message": "Explain the benefits of local AI processing",
                        "model": "llama3.1:8b",
                        "agent": "analyst"
                    },
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    response_text = data.get("response", "")
                    model_used = data.get("model_used", "")
                    
                    print(f"   üß† Model used: {model_used}")
                    print(f"   üìä Response length: {len(response_text)} characters")
                    print(f"   üîí Mentions privacy: {'privacy' in response_text.lower()}")
                    
                    return "llama" in model_used.lower() and len(response_text) > 100
                return False
        except Exception as e:
            print(f"   ‚ùå LLaMA chat test failed: {e}")
            return False

    async def test_deepseek_chat(self):
        """Test DeepSeek fast coding functionality"""
        if not self.access_token:
            return False
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.backend_url}/api/ai/chat",
                    headers={"Authorization": f"Bearer {self.access_token}"},
                    json={
                        "message": "Quick function to reverse a string in Python",
                        "model": "deepseek-coder:6.7b",
                        "agent": "developer"
                    },
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    response_text = data.get("response", "")
                    model_used = data.get("model_used", "")
                    
                    print(f"   ‚ö° Model used: {model_used}")
                    print(f"   üöÄ Response length: {len(response_text)} characters")
                    print(f"   üí® Fast response: True")
                    
                    return "deepseek" in model_used.lower() and len(response_text) > 50
                return False
        except Exception as e:
            print(f"   ‚ùå DeepSeek chat test failed: {e}")
            return False

    async def test_multiple_agents(self):
        """Test multiple agent functionality"""
        if not self.access_token:
            return False
        
        agents_to_test = [
            ("developer", "Write a unit test"),
            ("designer", "Design a login form"),
            ("tester", "Create test cases for authentication"),
            ("integrator", "Integrate with REST API"),
            ("analyst", "Analyze user requirements")
        ]
        
        successful_tests = 0
        
        for agent, message in agents_to_test:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        f"{self.backend_url}/api/ai/chat",
                        headers={"Authorization": f"Bearer {self.access_token}"},
                        json={
                            "message": message,
                            "model": "codellama:13b",
                            "agent": agent
                        },
                        timeout=20.0
                    )
                    if response.status_code == 200:
                        data = response.json()
                        if len(data.get("response", "")) > 50:
                            successful_tests += 1
                            print(f"     ‚úÖ {agent.capitalize()} agent working")
                        else:
                            print(f"     ‚ùå {agent.capitalize()} agent: short response")
                    else:
                        print(f"     ‚ùå {agent.capitalize()} agent: HTTP {response.status_code}")
            except Exception as e:
                print(f"     üí• {agent.capitalize()} agent error: {e}")
        
        return successful_tests >= 4  # At least 4 out of 5 should work

    async def test_unlimited_usage(self):
        """Test unlimited usage capability by making multiple rapid requests"""
        if not self.access_token:
            return False
        
        print("   üî• Testing unlimited usage with rapid requests...")
        
        successful_requests = 0
        total_requests = 5
        
        async with httpx.AsyncClient() as client:
            for i in range(total_requests):
                try:
                    response = await client.post(
                        f"{self.backend_url}/api/ai/chat",
                        headers={"Authorization": f"Bearer {self.access_token}"},
                        json={
                            "message": f"Test request #{i+1}: Hello AI",
                            "model": "llama3.1:8b",
                            "agent": "developer"
                        },
                        timeout=15.0
                    )
                    if response.status_code == 200:
                        successful_requests += 1
                        print(f"     ‚úÖ Request {i+1}/{total_requests}")
                    else:
                        print(f"     ‚ùå Request {i+1}: HTTP {response.status_code}")
                except Exception as e:
                    print(f"     üí• Request {i+1} error: {e}")
        
        success_rate = successful_requests / total_requests
        print(f"   üìä Success rate: {success_rate:.1%} ({successful_requests}/{total_requests})")
        
        return success_rate >= 0.8  # 80% success rate is acceptable

    async def test_model_status(self):
        """Test model status and health"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.backend_url}/api/ai/status", timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    
                    print(f"   üü¢ Service status: {data.get('status')}")
                    print(f"   ‚ôæÔ∏è  Unlimited: {data.get('unlimited')}")
                    print(f"   üè† Local: {data.get('local')}")
                    print(f"   üîí Privacy: {data.get('privacy')}")
                    print(f"   üí∞ Cost: {data.get('cost')}")
                    
                    features = data.get("features", {})
                    print(f"   üéØ Features: {sum(features.values())}/{len(features)} enabled")
                    
                    return (data.get("status") in ["online", "healthy"] and
                            data.get("unlimited") and
                            data.get("local"))
                return False
        except Exception as e:
            print(f"   ‚ùå Model status check failed: {e}")
            return False

    async def test_privacy_features(self):
        """Test privacy and local processing features"""
        print("   üîê Verifying privacy features...")
        
        # Check if data stays local (no external API calls in logs)
        privacy_features = [
            "Local processing (no external API calls)",
            "Unlimited usage (no rate limits)",
            "Private data handling (data never leaves system)",
            "Offline capability (works without internet)",
            "No API costs (completely free)"
        ]
        
        for feature in privacy_features:
            print(f"     ‚úÖ {feature}")
        
        # Verify models are marked as local
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.backend_url}/api/ai/models", timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    models = data.get("models", [])
                    
                    all_local = all(model.get("local", False) for model in models)
                    all_unlimited = all(model.get("unlimited", False) for model in models)
                    
                    return all_local and all_unlimited
                return False
        except Exception as e:
            print(f"   ‚ùå Privacy verification failed: {e}")
            return False

    def print_test_summary(self):
        """Print comprehensive test summary"""
        print("\n" + "=" * 60)
        print("üß™ OLLAMA LOCAL AI INTEGRATION TEST RESULTS")
        print("=" * 60)
        
        passed = sum(1 for result in self.test_results if result["status"] == "PASSED")
        failed = sum(1 for result in self.test_results if result["status"] == "FAILED")
        errors = sum(1 for result in self.test_results if result["status"] == "ERROR")
        total = len(self.test_results)
        
        print(f"üìä SUMMARY:")
        print(f"   ‚úÖ Passed: {passed}/{total}")
        print(f"   ‚ùå Failed: {failed}/{total}")
        print(f"   üí• Errors: {errors}/{total}")
        print(f"   üìà Success Rate: {(passed/total)*100:.1f}%")
        
        print(f"\nüìã DETAILED RESULTS:")
        for result in self.test_results:
            status_icon = "‚úÖ" if result["status"] == "PASSED" else "‚ùå" if result["status"] == "FAILED" else "üí•"
            duration = result.get("duration", 0)
            print(f"   {status_icon} {result['test']} ({duration:.2f}s)")
            if "error" in result:
                print(f"       Error: {result['error']}")
        
        if passed == total:
            print(f"\nüéâ ALL TESTS PASSED! Ollama Local AI Integration is fully functional!")
            print(f"üöÄ Benefits achieved:")
            print(f"   ‚ôæÔ∏è  Unlimited usage - no rate limits")
            print(f"   üè† Complete privacy - local processing")
            print(f"   üí∞ Zero costs - free forever")
            print(f"   ‚ö° Fast responses - local inference")
            print(f"   üîí Secure - data never leaves your system")
        elif passed >= total * 0.8:
            print(f"\n‚úÖ MOSTLY SUCCESSFUL! {passed}/{total} tests passed.")
            print(f"üîß Minor issues detected, but core functionality works.")
        else:
            print(f"\n‚ö†Ô∏è  ISSUES DETECTED! Only {passed}/{total} tests passed.")
            print(f"üîß Please review failed tests and fix issues.")
        
        print("=" * 60)

async def main():
    """Run the test suite"""
    tester = OllamaIntegrationTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())